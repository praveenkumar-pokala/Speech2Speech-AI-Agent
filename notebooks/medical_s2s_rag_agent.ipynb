{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e6ee295",
   "metadata": {},
   "source": [
    "# ü©∫ Medical Speech-to-Speech RAG Agent (Doctor‚ÄìPatient, Multi-turn)\n",
    "\n",
    "This notebook demonstrates a **low-latency speech-to-speech medical reasoning agent** with multi-turn memory and RAG, and runs a Gradio UI **inline**.\n",
    "\n",
    "> ‚ö†Ô∏è Educational only, not a real medical device."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05253e83",
   "metadata": {},
   "source": [
    "## 1. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f233361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc2272",
   "metadata": {},
   "source": [
    "## 2. Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf0c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gradio as gr\n",
    "from src.asr_tts import ASRWrapper, TTSWrapper\n",
    "from src.rag_agent import MedicalRAGAgent\n",
    "\n",
    "asr = ASRWrapper()\n",
    "tts = TTSWrapper()\n",
    "agent = MedicalRAGAgent()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f97a17f",
   "metadata": {},
   "source": [
    "## 3. Define chat functions (text and speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c2263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "def chat_text(user_message: str, history: List[Tuple[str, str]]):\n",
    "    if history is None:\n",
    "        history = []\n",
    "    if not user_message.strip():\n",
    "        return \"\", history\n",
    "    reply = agent.generate_response(user_message, history)\n",
    "    history.append((user_message, reply))\n",
    "    return \"\", history\n",
    "\n",
    "def chat_speech(audio, history: List[Tuple[str, str]]):\n",
    "    if history is None:\n",
    "        history = []\n",
    "    if audio is None:\n",
    "        return \"No audio detected.\", None, history\n",
    "    user_text = asr.speech_to_text(audio)\n",
    "    reply = agent.generate_response(user_text, history)\n",
    "    history.append((user_text, reply))\n",
    "    sr, audio_out = tts.text_to_speech(reply)\n",
    "    return reply, (sr, audio_out), history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a704e3",
   "metadata": {},
   "source": [
    "## 4. Build Gradio UI (inline in notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f04a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # ü©∫ Medical Speech-to-Speech RAG Agent (Demo - Notebook)\n",
    "\n",
    "    - Speech ‚Üî Speech\n",
    "    - RAG over tiny medical corpus\n",
    "    - Multi-turn memory\n",
    "    - Gradio inline UI\n",
    "    \"\"\")\n",
    "\n",
    "    with gr.Tab(\"Speech ‚Üî Speech\"):\n",
    "        state = gr.State([])\n",
    "        audio_in = gr.Audio(source=\"microphone\", type=\"numpy\", label=\"Speak your symptoms\")\n",
    "        with gr.Row():\n",
    "            text_out = gr.Textbox(label=\"Agent Response (Text)\", lines=4)\n",
    "            audio_out = gr.Audio(label=\"Agent Response (Audio)\")\n",
    "\n",
    "        audio_in.stop_recording(\n",
    "            fn=chat_speech,\n",
    "            inputs=[audio_in, state],\n",
    "            outputs=[text_out, audio_out, state],\n",
    "        )\n",
    "\n",
    "    with gr.Tab(\"Text Chat\"):\n",
    "        state2 = gr.State([])\n",
    "        chatbot = gr.Chatbot()\n",
    "        msg = gr.Textbox(label=\"Describe your symptoms\")\n",
    "\n",
    "        def _chat_proxy(message, history):\n",
    "            new_msg, new_hist = chat_text(message, history)\n",
    "            return new_msg, new_hist\n",
    "\n",
    "        msg.submit(_chat_proxy, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "demo.launch(inline=True)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
